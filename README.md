# Benchmarking-NumPy-vs-PyTorch-for-Matrix-and-Vector-Operations
Benchmarking NumPy vs PyTorch  for Matrix and Vector Operations


Computational efficiency is crucial when performing large-scale matrix and vector operations in machine learning, data science, and scientific computing. The choice of the computational backend—NumPy (CPU-based) vs PyTorch (CPU & MPS-based)—can significantly impact execution speed, especially on Apple Silicon (M1/M2/M3 Macs), where Metal Performance Shaders (MPS) provide GPU acceleration.

This project aims to compare the execution time of essential matrix operations using: • NumPy (CPU-based computations) • PyTorch (CPU-based computations) • PyTorch (MPS-based computations on Apple GPUs)

The results will help determine which framework is best suited for performing high-dimensional numerical computations efficiently.
